import os
import numpy as np
import itertools
import torch
import matplotlib.pyplot as plt
from matplotlib.legend_handler import HandlerLine2D
from sklearn import metrics
from csv import DictReader


def split_csv_dict(csv_filepath):
    fps = []
    labels = []

    for row in DictReader(open(csv_filepath)):
        fps.append(row['Id'])
        labels.append(row['Class'])

    return fps, labels


def plot_loss_and_accurate(train_dict, test_dict):
    label1, = plt.plot(train_dict.keys(), train_dict.values(), "g-", label="Training accurate per epoch")
    label2, = plt.plot(test_dict.keys(), test_dict.values(), "y-",
                       label="Test accurate per epoch")

    plt.legend(handler_map={label1: HandlerLine2D(numpoints=4)})
    plt.legend(handler_map={label2: HandlerLine2D(numpoints=4)})
    plt.show()


def write_pred(model, test_loader, device):
    model.eval()
    y_true = []
    y_pred = []
    with open('test.pred', 'w') as f:
        for batch_data in test_loader:
            data, label = batch_data[0].to(device), batch_data[1].to(device)
            output = model(data)
            pred = output.data.max(1, keepdim=True)[1]
            preds = pred.cpu()
            y_true.append(label)
            y_pred.append(pred[0].numpy())

            for pred in preds:
                f.writelines(str(pred[0].numpy()) + '\n')
    matrix = metrics.confusion_matrix(y_true, y_pred)
    plot_confusion_matrix(matrix, normalize=True)


def plot_confusion_matrix(cm, normalize=False, title='Confusion matrix', cmap=plt.cm.Blues):
    plt.imshow(cm, interpolation='nearest', cmap=cmap)
    plt.title(title)
    plt.colorbar()

    fmt = '.2f' if normalize else 'd'
    thresh = cm.max() / 2.
    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):
        plt.text(j, i, format(cm[i, j], fmt),
                 horizontalalignment="center",
                 color="white" if cm[i, j] > thresh else "black")

    plt.tight_layout()
    plt.ylabel('True label')
    plt.xlabel('Predicted label')
    plt.show()


def gen_train_and_dev_data_sets(root_dir_path, classes_list, ratio=0.2):
    train_set = {}
    dev_set = {}
    for i in range(len(classes_list)):
        class_path = root_dir_path + '/' + classes_list[i]
        class_files = os.listdir(class_path)
        for file in class_files:
            path = class_path + '/' + file
            rand = np.random.uniform(0, 1)
            if (rand > ratio):
                train_set[path] = i + 1
            else:
                dev_set[path] = i + 1
    return train_set.keys(), train_set.values(), dev_set.keys(), dev_set.values()


def get_data_info(info_file_path):
    with open(info_file_path, 'r') as f:
        data_folder = f.readline().replace('\r', '').replace('\n', '')
        classes_list = f.readline().replace('\r', '').replace('\n', '')
        classes_list = classes_list.split(' ')
        return data_folder, classes_list
