import sys
import malConv
import torch
import train
import utils as ut
import torch.nn as nn
from torch.utils.data import DataLoader
from ExeDataset import ExeDataset


def main(use_cpu=1, batch_size=16, num_of_classes=8, first_n_byte=2000000):
    model = malConv.MalConv(num_of_classes)
    if torch.cuda.is_available() and torch.cuda.device_count() > 0:
        print("gpu!!!!!!!")
        device = torch.device("cuda:0")
        model = nn.Sequential(model)
        model = nn.DataParallel(model)
        model.to(device)
    else:
        device = torch.device("cpu")

    # Extracting data to data loaders.
    data_folder, classes_list = ut.get_data_info('classes.txt')
    fps_train, y_train, fps_dev, y_dev = ut.gen_train_and_dev_data_sets(data_folder, classes_list)

    train_loader = DataLoader(ExeDataset(fps_train, y_train, first_n_byte),
                              batch_size=batch_size, shuffle=True, num_workers=use_cpu)
    test_loader = DataLoader(ExeDataset(fps_dev, y_dev, first_n_byte),
                             batch_size=batch_size, shuffle=False, num_workers=use_cpu)

    train.train_on(model, train_loader, test_loader, len(y_dev), len(y_train), device, batch_size)


if __name__ == '__main__':
    if len(sys.argv) > 1:
        use_cpu, batch_size, num_of_classes = int(sys.argv[1]), int(sys.argv[2]), int(sys.argv[3])
        main(use_cpu, batch_size, num_of_classes)
    else:
        main()
